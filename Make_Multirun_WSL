WANDB_API_KEY=b3fb3695850f3bdebfee750ead3ae8230c14ea07
RUN_FILE="jsrl-CORL/algorithms/finetune/no_ray_trainer.py"
DF=Dockerfile
DOCKER_EXTRAS=-e WANDB_API_KEY=$(WANDB_API_KEY) -it --shm-size=10.24gb --cpus 16 -v ./algorithms/finetune/checkpoints:/workspace/checkpoints -v ./algorithms/finetune/wandb:/workspace/wandb -v .:/workspace/jsrl-CORL

build:
	yes | docker container prune

	docker build \
	-f $(DF) \
	-t jsrl-corl \
	.

run1:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --device cpu --env AdroitHandRelocate-v1 --offline_iterations 1000000 --online_iterations 1000000 --n_curriculum_stages 1 --env_config '{"reward_type": "sparse", "max_episode_steps": 200}' --eval_freq 100 --tolerance 0.05 --beta 10 --learner_frac 0.05 --iql_tau 0.9 --checkpoints_path checkpoints --horizon_fn time_step --normalize False ;

runant:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --horizon_fn time_step --checkpoints_path checkpoints --env antmaze-umaze-v2 --normalize True --tolerance 0.9 --normalize_reward True --enable_rollback False --iql_deterministic False --beta 10 --learner_frac -1 --correct_learner_action 0.1 --iql_tau 0.9 --eval_freq 10000 --n_episodes 100 --offline_iterations 100000 --online_iterations 1000000 ;

build_and_run: build run1

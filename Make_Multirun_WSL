WANDB_API_KEY=b3fb3695850f3bdebfee750ead3ae8230c14ea07
RUN_FILE="jsrl-CORL/algorithms/finetune/ray_trainer.py"
DF=Dockerfile
DOCKER_EXTRAS=-e WANDB_API_KEY=$(WANDB_API_KEY) -it --shm-size=10.24gb --cpus 4 -v ./algorithms/finetune/checkpoints:/workspace/checkpoints -v ./algorithms/finetune/wandb:/workspace/wandb -v .:/workspace/jsrl-CORL

build:
	yes | docker container prune

	docker build \
	-f $(DF) \
	-t jsrl-corl \
	.

run1:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --horizon_fn time_step --checkpoints_path checkpoints --env antmaze-umaze-v2 --static True --normalize True --tolerance 0.9 --normalize_reward True --enable_rollback False --iql_deterministic False --beta 10 --learner_frac 0.25 --correct_learner_action 1 --iql_tau 0.9 --eval_freq 10000 --n_episodes 100 --offline_iterations 0 --online_iterations 1000000 --pretrained_policy_path jsrl-CORL/algorithms/finetune/checkpoints/IQL-antmaze-umaze-v2-offline/checkpoint_999999.pt --device cpu  ;


run2:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --horizon_fn time_step --checkpoints_path checkpoints --env antmaze-medium-play-v2  --static True --normalize True --tolerance 0.9 --normalize_reward True --enable_rollback False --iql_deterministic False --beta 10 --learner_frac 0.25 --correct_learner_action 1.0 --iql_tau 0.9 --eval_freq 10000 --n_episodes 100 --pretrained_policy_path jsrl-CORL/algorithms/finetune/checkpoints/IQL-antmaze-medium-play-v2-offline/checkpoint_999999.pt --offline_iterations 0 --online_iterations 1000000 --device cpu  ;


run3:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --horizon_fn time_step --checkpoints_path checkpoints --env antmaze-large-play-v2 --static True --normalize True --tolerance 0.9 --normalize_reward True --enable_rollback False --iql_deterministic False --beta 10 --learner_frac 0.25 --correct_learner_action 1.0 --iql_tau 0.9 --eval_freq 10000 --n_episodes 100 --pretrained_policy_path jsrl-CORL/algorithms/finetune/checkpoints/IQL-antmaze-large-play-v2-offline/checkpoint_999999.pt --offline_iterations 0 --online_iterations 1000000 --device cpu ;

run4:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --env CombinationLock-v0 --static true --learner_frac 1 --online_buffer_size 64 --guide_heuristic_fn combination_lock --offline_iterations 0 --env_config '{"horizon": 10}' --tolerance 0.75 --n_episodes 250 --eval_freq 1 --batch_size 10 --beta 10 --iql_tau 0.9 --horizon_fn time_step --name IQL-test --device cpu --online_iterations 300 --seed 0 --iql_deterministic True --enable_rollback True --sample_rate 0.9 ;

run5:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --env CombinationLock-v0 --static true --learner_frac 1 --online_buffer_size 64 --guide_heuristic_fn combination_lock --offline_iterations 0 --env_config '{"horizon": 10}' --tolerance 0.25 --n_episodes 250 --eval_freq 1 --batch_size 10 --beta 10 --iql_tau 0.9 --horizon_fn time_step --name IQL-test --device cpu --online_iterations 300 --seed 0 --iql_deterministic True --enable_rollback True --sample_rate 0.9 ;

run6:
	docker run $(DOCKER_EXTRAS) \
	jsrl-corl python $(RUN_FILE) --env CombinationLock-v0 --linear_decay true --learner_frac -1 --online_buffer_size 64 --guide_heuristic_fn combination_lock --offline_iterations 0 --env_config '{"horizon": 10}' --tolerance 0.25 --n_episodes 250 --eval_freq 1 --batch_size 10 --beta 10 --iql_tau 0.9 --horizon_fn time_step --name IQL-test --device cpu --online_iterations 300 --seed 0 --iql_deterministic True --enable_rollback True --sample_rate 0.9 ;

build_and_run: build run4 run5 run6
